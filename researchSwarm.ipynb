{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4436c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from IPython.display import Image, display\n",
    "from PIL import Image as PILImage\n",
    "import io\n",
    "from enum import Enum\n",
    "from typing import Annotated\n",
    "import os\n",
    "import json\n",
    "import arxiv\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from langchain_core.messages import ToolMessage\n",
    "import operator\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from composio_langgraph import Action, ComposioToolSet, App\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"COMPOSIO_API_KEY\"] = os.getenv(\"COMPOSIO_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dafbdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Literal\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.types import Command\n",
    "from langchain_core.messages import HumanMessage, trim_messages\n",
    "class State(MessagesState):\n",
    "    next: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca71d1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Literal\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.types import Command\n",
    "from langchain_core.messages import HumanMessage, trim_messages\n",
    "\n",
    "\n",
    "class State(MessagesState):\n",
    "    next: str\n",
    "\n",
    "\n",
    "def make_research_channel_decider(llm: BaseChatModel, members: list[str]) -> str:\n",
    "    options = members\n",
    "    system_prompt = (\n",
    "        \"You are a research channel decider. You will need to decide which\"\n",
    "        \"medium of research is best to obtain the information requested by the user.\"\n",
    "        \"You will be given a prompt and your job is to decide which medium\"\n",
    "        f\"from the following list of of options {members} is best to use.\"\n",
    "    )\n",
    "\n",
    "    class Router(TypedDict):\n",
    "        \"\"\"Worker to route to next. If no workers needed, route to FINISH.\"\"\"\n",
    "\n",
    "        next: Literal[*options]\n",
    "\n",
    "    def channel_decider_node(state: State) -> Command[Literal[*members, \"__end__\"]]:\n",
    "        \"\"\"An LLM-based router.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "        ] + state[\"messages\"]\n",
    "        response = llm.with_structured_output(Router).invoke(messages)\n",
    "        goto = response[\"next\"]\n",
    "\n",
    "        return Command(goto=goto, update={\"next\": goto})\n",
    "\n",
    "    return channel_decider_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad91d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "search_agent = create_react_agent(llm)\n",
    "\n",
    "\n",
    "def search_node(state: State) -> Command[Literal[\"channel_decider\"]]:\n",
    "    result = search_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"search\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to always finish and end their execution cycle\n",
    "        goto=\"FINISH\",\n",
    "    )\n",
    "\n",
    "youtube_agent = create_react_agent(llm)\n",
    "def youtube_node(state: State) -> Command[Literal[\"channel_decider\"]]:\n",
    "    result = search_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"youtube\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to always finish and end their execution cycle\n",
    "        goto=\"FINISH\",\n",
    "    )\n",
    "\n",
    "\n",
    "research_channel_decider_node = make_research_channel_decider(llm, [\"search\", \"youtube\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e47008",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_builder = StateGraph(State)\n",
    "research_builder.add_node(\"channel_decider\", research_channel_decider_node)\n",
    "research_builder.add_node(\"search\", search_node)\n",
    "research_builder.add_node(\"youtube\", youtube_node)\n",
    "\n",
    "research_builder.add_edge(START, \"supervisor\")\n",
    "research_graph = research_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734da4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(research_graph.get_graph().draw_mermaid_png()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
